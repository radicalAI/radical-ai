---
layout: main
---
## Radical AI Principles

1. We recognize that power is distributed unevenly, and People of Color, Black,
Indigenous, Womxn, Queer, Trans, Gender Non-Conforming, Poor, Dis-abled, and other
communities are pushed to the margins. We commit to <i>resisting</i> these
interlocking systems of oppression, including Racism, Coloniality, Casteism,
Heteropatriarchy, Capitalism, and Ableism. We commit to <i>striving</i> toward
collective liberation.[^1]
2. We center radical work by communities at the margins.
3. We recognize that all technologies rearrange power.
4. We are critical of how AI shifts power. In particular, we recognize AI is
frequently extractive, exploitative, surveilling, controlling, prescriptive,
and reductionist. We recognize AI frequently prevents consent, deliberation,
investigation, intervention, resistance, and agency.
5. We recognize the privilege of being adjacent to institutions creating
technologies. We use this privilege to <i>step up</i> to expose oppressive
technologies and to center those harmed, and to <i>step back</i>, ceding power,
listening, and co-conspiring when those voices speak. 
6. We value dreaming up and building human/AI systems that put power in the
hands of the people. We recognize this is vulnerable and important work.
7. We recognize that reforming harmful AI can reduce harm to some while
legitimizing (“ethics-washing”) systems still harming others[^2]. Only by
understanding the root of the harm and centering those most impacted can we
make these complex tactical decisions, deciding when to minimize harm done by
AI and when to call for its abolition[^3]. We recognize that no one has a
‘view from nowhere’[^4]. We practice reflexivity, naming who we are, how who we
are influences what we do, and whose perspectives are missing.

---
[^1]: This principle is informed by <i>The Combahee River Collective Statement</i>

[^2]: This tension is prominent in efforts such as ‘AI for Social Good,’ ‘AI
    Ethics,’ and ‘Algorithmic Fairness, Accountability, and Transparency’. These
    are not inherently Radical AI objectives: Creating an AI, for example, to
    decide whether to jail someone in a way that is “Fair,” “Accountable,” and
    “Transparent” (a common motivation for work in AI for Social Justice areas)
    doesn’t inherently question the Prison Industrial Complex it is created for
    and the shifts power to the carceral system. Radical AI is a
    <i>response</i> to these and similar AI for Social Justice efforts: Radical
    AI moves to recenter the affected marginalized communities and to ask how
    these technologies redistribute power in the world.

[^3]: This principle is informed by Audre Lorde’s <i>The Master's Tools Will
    Never Dismantle the Master's House</i>

[^4]: The “view from nowhere” is developed in Donna Haraway’s Situated
    Knowledges
